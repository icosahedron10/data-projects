## Jake Madsen's Data Portfolio
# Intro

My name is Jake Madsen and I am a graduate student at Colorado State University pursuing a Master of Applied Statistics. With my anticipated graduation in July 2023, I am deeply invested in the field of data, its potential to solve complex problems, and the recent exponential growth in global data volume. My goal is to make a positive impact in this field by utilizing my skills and knowledge to create innovative solutions. The following are selected examples of my past projects and experiences in the field of data analysis.

# Spaceship Titanic
[link](https://github.com/icosahedron10/spaceship-titanic/blob/main/Spaceship_Titanic.ipynb)

In 2912, a cosmic mystery needs to be solved using data science skills. The Spaceship Titanic, an interstellar passenger liner, collided with a spacetime anomaly while on its maiden voyage, resulting in almost half of its 13,000 passengers being transported to an alternate dimension. The task is to predict which passengers were transported by the anomaly using records from the spaceship's damaged computer system in order to assist rescue teams.

To solve this mystery, XGBoost and imputation techniques will be utilized. XGBoost is a powerful machine learning algorithm for classification and regression that has shown to be effective for many real-world problems. Imputation techniques will be used to handle missing or corrupted data in the records recovered from the spaceship's damaged computer system. By combining these two tools, the goal is to accurately predict which passengers were transported by the anomaly and help rescue them.

# The Effect of Five Factors on Elapsed Time Perception in a Visual Medium
[link](https://github.com/icosahedron10/data-projects/blob/main/The%20Effect%20of%20Five%20Factors%20on%20Elapsed%20Time%20Perception%20in%20a%20Visual%20Medium.pdf)

This project was completed as the capstone to my undergraduate degree in Mathematics.
>Abstract: We consider the effects of five forms of stimuli on perception of elapsed time while watching short, animated videos in a 2<sup>5âˆ’1</sup> fractional-factorial model. Similar to what consumers might experience in a digital waiting environment, the videos involve simple animated loops that repeat multiple times. The videos differ on five factors alone: the presence of an auditory chime, the use of color, contrast between the background and the foreground animation, the length of the video, and the periodicity of the loops. For each factor, half of the videos produced had the factor at its low level and half at its high level. Participants were shown one of the treatments and afterward asked to estimate the length of the video (n = 271). Four of five factors were found to have a statistically significant effect on perceived video length, along with two interactions.

# CIFAR10 Classification
[link](https://github.com/icosahedron10/cifar10-cnn/blob/main/CIFAR10.ipynb)

The CIFAR-10 dataset is widely used for image classification tasks and has been a benchmark in the field. This notebook aims to introduce the different layers of CNNs using CIFAR-10, including convolutional, pooling, normalizing, and fully connected layers, and explain how they work together for accurate image classification. The goal with this notebook is to provide an introductory understanding of CNNs and their implementation, and equip readers with the knowledge to build their own CNNs for image classification tasks.

# Fraud Detection
link goes here

The field of fraud detection is a growing concern for financial institutions, as the cost of fraud can be substantial and have a long-lasting impact on customers. In order to address this problem, data science techniques can be used to build models that can detect fraudulent activity in real-time. In this project, we will be using the IEEE-CIS Fraud Detection data set to build a classification model to detect fraudulent transactions.

The IEEE-Cis Fraud Detection data set consists of approximately half a million transactions and features over 400 variables. This data set is imbalanced, with only a small percentage of transactions labeled as fraudulent. The goal of this project is to build a model that can accurately classify fraudulent transactions while also controlling for false positive errors.

To accomplish this, we will be using a variety of data preprocessing and modeling techniques. We will begin by exploring the data and examining the distribution of the features and target variable. Next, we will perform feature engineering to create new variables and reduce the dimensionality of the data. Finally, we will train several classification algorithms, including logistic regression, decision trees, and random forests, to build our final model. By combining these techniques, we aim to build a model that is both accurate and robust in detecting fraudulent transactions.
